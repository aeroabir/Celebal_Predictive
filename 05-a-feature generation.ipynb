{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_df = pd.read_csv('all_inverters.csv')\n",
    "# inv_df.head()\n",
    "\n",
    "target_codes = [7006, 3511, 7502, 7501, 3504, 6448, 1500, 7704]\n",
    "alarm_df = pd.read_csv('all_alarms.csv')\n",
    "alarm_df = alarm_df[alarm_df[\"Error Code\"].isin(target_codes)]\n",
    "alarm_df = alarm_df[(alarm_df.hod >= 6) & (alarm_df.hod <= 18)]  # original (6,17)\n",
    "print(alarm_df.shape)\n",
    "inverters = sorted(alarm_df[\"Controller Name\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inverter-labels-v3.pkl', 'rb') as handle:\n",
    "    inv_labels = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = {'inverters': [], 'positive': [], 'negative': []}\n",
    "label_col = 'label_1h'\n",
    "for inv in inv_labels.keys():\n",
    "    x = inv_labels[inv]\n",
    "    y = dict(x[label_col].value_counts())\n",
    "    label_df['inverters'].append(inv)\n",
    "    if 1 in y:\n",
    "        label_df['positive'].append(y[1])\n",
    "    else:\n",
    "        label_df['positive'].append(0)\n",
    "    label_df['negative'].append(y[0])\n",
    "label_df = pd.DataFrame(label_df)\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.to_csv('inverter-faults-v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ratio\n",
    "mask = label_df['positive'] > 10\n",
    "total = label_df[mask][['positive', 'negative']].apply(np.sum, axis=0)\n",
    "100 * total['positive'] / (total['positive'] + total['negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_funs = [np.mean, np.std, 'max', 'median']\n",
    "\n",
    "def rolling_features(df, start_step, window_size, funcs):\n",
    "    features = df.shift(start_step).rolling(window_size, min_periods=window_size).agg(funcs)\n",
    "    features.columns = [\"{}_{}{}\".format(x[0], x[1], str(window_size)) for x in features.columns]\n",
    "    return features\n",
    "\n",
    "def create_features(df, colnames, ROLLING_WINDOWS):\n",
    "    # Feature engineering\n",
    "    df[\"day\"] = df[TIMESTAMP_COL_NAME].apply(lambda x: x.day)\n",
    "    df[\"dayofweek\"] = df[TIMESTAMP_COL_NAME].apply(lambda x: x.dayofweek)\n",
    "    df[\"weekofyear\"] = df[TIMESTAMP_COL_NAME].apply(lambda x: x.isocalendar()[1])\n",
    "    df[\"month\"] = df[TIMESTAMP_COL_NAME].apply(lambda x: x.month)\n",
    "\n",
    "    # exclude the current time data - so shift rolling calcs by 1\n",
    "    start_step = 1 \n",
    "    for col in colnames:\n",
    "        for window in ROLLING_WINDOWS:\n",
    "            feats = rolling_features(df[[col]], start_step=1, window_size=window, funcs=np_funs).reset_index(drop=True)\n",
    "            df = pd.concat([df, feats], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [x*12*24 for x in [1, 2, 3, 7, 14, 21, 30]]\n",
    "TIMESTAMP_COL_NAME = 'date'\n",
    "data = []\n",
    "for inverter in inv_labels.keys():\n",
    "    x = inv_labels[inverter]\n",
    "    y = dict(x['label'].value_counts())\n",
    "    if True in y and y[True] > 10:\n",
    "        features = ['IN.GMRX.CHAR.'+inverter+'.Active Power (kW)', \n",
    "                'IN.GMRX.CHAR.WS-20 MW.Module Temperature (°C)',\n",
    "                'IN.GMRX.CHAR.WS-20 MW.POA Irradiance (w/m²)',\n",
    "                'IN.GMRX.CHAR.WS-5 MW.Module Temperature (°C)',\n",
    "                'IN.GMRX.CHAR.WS-5 MW.POA Irradiance (w/m²)'\n",
    "               ]\n",
    "        columns = ['date'] + features\n",
    "        inv_df_i = inv_df[columns].copy()\n",
    "        inv_df_i['date'] = pd.to_datetime(inv_df_i[\"date\"])\n",
    "        inv_df_i.rename(columns={'IN.GMRX.CHAR.'+inverter+'.Active Power (kW)': 'power',\n",
    "                                'IN.GMRX.CHAR.WS-20 MW.Module Temperature (°C)': 'temp1',\n",
    "                                'IN.GMRX.CHAR.WS-20 MW.POA Irradiance (w/m²)': 'rad1',\n",
    "                                'IN.GMRX.CHAR.WS-5 MW.Module Temperature (°C)': 'temp2',\n",
    "                                'IN.GMRX.CHAR.WS-5 MW.POA Irradiance (w/m²)': 'rad2'}, inplace=True)\n",
    "        inv_df_i['hour'] = inv_df_i.date.dt.hour\n",
    "        df_ = create_features(inv_df_i, colnames=['power', 'temp1', 'rad1'], ROLLING_WINDOWS=windows)\n",
    "        df_ = x.merge(df_, on='date', how='left')\n",
    "        df_['inverter'] = inverter\n",
    "        y = df_[label_col].value_counts()\n",
    "        print(inverter, x.shape[0], df_.shape[0], y[1], y[0], y[1]/(y[1]+y[0]))\n",
    "        data.append(df_)\n",
    "        sys.exit(\"HERE\")\n",
    "    else:\n",
    "        continue\n",
    "data = pd.concat(data, axis=0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total2 = data[label_col].value_counts()\n",
    "100 * total2[1] / (total2[0] + total2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('inverter-data-v03.pkl', 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
