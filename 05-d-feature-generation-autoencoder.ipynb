{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation Using seq2seq/autoencoder models\n",
    "\n",
    "    - use seq2seq architecture to generate embeddings for multi-dimensional time series\n",
    "    - use target = input for AutoEncoder setup\n",
    "    - use the next day history as target for getting a different embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the alarm classification data\n",
    "with open('inverter-data-cnn-v01.pkl', 'rb') as handle:\n",
    "    x_dict, y_dict, label_df = pickle.load(handle)\n",
    "    \n",
    "x_all, y_all = [], []\n",
    "for inv in x_dict:\n",
    "    x_ii, y_ii = x_dict[inv], y_dict[inv]\n",
    "    x_all.append(x_ii)\n",
    "    y_all.append(y_ii)\n",
    "\n",
    "x_all = np.concatenate(x_all, axis=0)\n",
    "y_all = np.concatenate(y_all, axis=0)\n",
    "x_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from 04-c file\n",
    "with open('autoencoder-data-v01.pkl', 'rb') as handle:\n",
    "    x_all, y_all = pickle.load(handle)\n",
    "x_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_all[0, :, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmax = np.amax(x_all, axis=(0, 1))\n",
    "print(xmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymax = np.amax(y_all, axis=(0, 1))\n",
    "print(ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = x_all / xmax\n",
    "y_norm = y_all / ymax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amax(x_norm, axis=(0, 1)), np.amax(y_norm, axis=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot(x_all[0, :, 0])\n",
    "plt.title(\"Power\")\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.plot(x_all[0, :, 1])\n",
    "plt.title(\"Temperature\")\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.plot(x_all[0, :, 2])\n",
    "plt.title(\"Irradiance\")\n",
    "\n",
    "# normalized\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.plot(x_norm[0, :, 0])\n",
    "\n",
    "# temperature\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.plot(x_norm[0, :, 1])\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.plot(x_norm[0, :, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15,12))\n",
    "ax = f.add_subplot(231)\n",
    "ax2 = f.add_subplot(232)\n",
    "ax3 = f.add_subplot(233)\n",
    "\n",
    "ax.plot(x_all[0, :, 0])\n",
    "ax2.plot(x_all[0, :, 1])\n",
    "ax3.plot(x_all[0, :, 2])\n",
    "\n",
    "ax4 = f.add_subplot(234)\n",
    "ax5 = f.add_subplot(235)\n",
    "ax6 = f.add_subplot(236)\n",
    "ax4.plot(x_norm[0, :, 0])\n",
    "ax5.plot(x_norm[0, :, 1])\n",
    "ax6.plot(x_norm[0, :, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm[0, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all[0, :, 2] / 18674.02929688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all[0, :, 2].max(), x_all[0, :, 2].max() / 18674.02929688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the target same as input - autoencoder or the next day history\n",
    "# X_train,  X_test, Y_train, Y_test = train_test_split(x_norm, x_norm, test_size=0.2)\n",
    "\n",
    "X_train,  X_test, Y_train, Y_test = train_test_split(x_norm, y_norm, test_size=0.2)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Decoder Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "embedding_dims = 256 #128\n",
    "rnn_units = 256 #128\n",
    "dense_units = 512 # 256\n",
    "Dtype = tf.float32   #used to initialize DecoderCell Zero state\n",
    "bidirectional = True\n",
    "loss_function = 'mse' # 'mae'\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = x_norm.shape[0]\n",
    "steps_per_epoch = BUFFER_SIZE//BATCH_SIZE\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "example_X, example_Y = next(iter(train_dataset))\n",
    "print(example_X.shape) \n",
    "print(example_Y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#ENCODER\n",
    "class EncoderNetwork(tf.keras.Model):\n",
    "    def __init__(self, rnn_units ):\n",
    "        super().__init__()\n",
    "        self.encoder_embedding = tf.keras.layers.Dense(rnn_units, activation='tanh')\n",
    "        if bidirectional:\n",
    "            basic_rnn = tf.keras.layers.LSTM(rnn_units, return_sequences=True, \n",
    "                                                     return_state=True )\n",
    "            self.encoder_rnnlayer = tf.keras.layers.Bidirectional(basic_rnn, merge_mode='concat')\n",
    "            self.state_converter = tf.keras.layers.Dense(rnn_units, activation='tanh')\n",
    "        else:\n",
    "            self.encoder_rnnlayer = tf.keras.layers.LSTM(rnn_units, return_sequences=True, \n",
    "                                                         return_state=True )\n",
    "            \n",
    "\n",
    "#DECODER-No attention        \n",
    "class DecoderNetwork2(tf.keras.Model):\n",
    "    def __init__(self, rnn_units, num_features):\n",
    "        super().__init__()\n",
    "        self.decoder_embedding = tf.keras.layers.Dense(rnn_units, activation='tanh')\n",
    "        self.decoder_rnncell = tf.keras.layers.LSTMCell(rnn_units)\n",
    "        # cannot use tf.keras.layers.LSTM since we need step-by-step during inference\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTMCell\n",
    "        # https://www.tensorflow.org/guide/keras/rnn\n",
    "        self.decoder = tf.keras.layers.RNN(self.decoder_rnncell, \n",
    "                                                    return_sequences=True, \n",
    "                                                    return_state=True)\n",
    "        self.dense_layer = tf.keras.layers.Dense(num_features, activation='relu')\n",
    "\n",
    "#DECODER\n",
    "class DecoderNetwork(tf.keras.Model):\n",
    "    def __init__(self, rnn_units):\n",
    "        super().__init__()\n",
    "        self.dense_layer = tf.keras.layers.Dense(1)\n",
    "        self.decoder_rnncell = tf.keras.layers.LSTMCell(rnn_units)\n",
    "        # Sampler\n",
    "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "        # Create attention mechanism with memory = None\n",
    "        self.attention_mechanism = self.build_attention_mechanism(dense_units,None,BATCH_SIZE*[Tx])\n",
    "        self.rnn_cell = self.build_rnn_cell(BATCH_SIZE)\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, sampler= self.sampler,\n",
    "                                                output_layer=self.dense_layer)\n",
    "\n",
    "    def build_attention_mechanism(self, units,memory, memory_sequence_length):\n",
    "        return tfa.seq2seq.LuongAttention(units, memory = memory, \n",
    "                                          memory_sequence_length=memory_sequence_length)\n",
    "        #return tfa.seq2seq.BahdanauAttention(units, memory = memory, memory_sequence_length=memory_sequence_length)\n",
    "\n",
    "    # wrap decodernn cell  \n",
    "    def build_rnn_cell(self, batch_size ):\n",
    "        rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnncell, self.attention_mechanism,\n",
    "                                                attention_layer_size=dense_units)\n",
    "        return rnn_cell\n",
    "    \n",
    "    def build_decoder_initial_state(self, batch_size, encoder_state,Dtype):\n",
    "        decoder_initial_state = self.rnn_cell.get_initial_state(batch_size = batch_size, \n",
    "                                                                dtype = Dtype)\n",
    "        decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state) \n",
    "        return decoder_initial_state\n",
    "\n",
    "\n",
    "def loss_function(y_pred, y):   \n",
    "    #shape of y [batch_size, seq_len, num_features]\n",
    "    #shape of y_pred [batch_size, seq_len, num_features]\n",
    "    if loss_function == 'mae':\n",
    "        mae = tf.keras.losses.MeanAbsoluteError()\n",
    "        loss = mae(y_true=y, y_pred=y_pred)\n",
    "    else:\n",
    "        mse = tf.keras.losses.MeanSquaredError()\n",
    "        loss = mse(y_true=y, y_pred=y_pred)\n",
    "#     mask = tf.logical_not(tf.math.equal(y,0))   #output 0 for y=0 else output 1\n",
    "#     mask = tf.cast(mask, dtype=loss.dtype)\n",
    "#     loss = mask* loss\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss\n",
    "\n",
    "def train_step(input_batch, output_batch, encoder_initial_cell_state):\n",
    "    #initialize loss = 0\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "#         encoder_emb_inp = tf.expand_dims(input_batch, -1)  # add the feature dimension, 1\n",
    "        encoder_emb_inp = encoderNetwork.encoder_embedding(input_batch)  # just a linear layer\n",
    "    \n",
    "        #[last step activations,last memory_state] of encoder passed as input to decoder Network\n",
    "        if bidirectional:\n",
    "            _, state_hf, state_hb, state_cf, state_cb = encoderNetwork.encoder_rnnlayer(encoder_emb_inp, \n",
    "                                                            initial_state =encoder_initial_cell_state)\n",
    "            state_h = encoderNetwork.state_converter(tf.concat([state_hf, state_hb], axis=-1))\n",
    "            state_c = encoderNetwork.state_converter(tf.concat([state_cf, state_cb], axis=-1))\n",
    "        else:\n",
    "            _, state_h, state_c = encoderNetwork.encoder_rnnlayer(encoder_emb_inp, \n",
    "                                                            initial_state =encoder_initial_cell_state)\n",
    "        \n",
    "        encoder_state = [state_h, state_c]\n",
    "\n",
    "        # even if there is no start/end we need to shift the input\n",
    "        # Prepare correct Decoder input & output sequence data\n",
    "        decoder_input = output_batch[:,:-1] # ignore <end>\n",
    "        #compare logits with timestepped +1 version of decoder_input\n",
    "        decoder_output = output_batch[:,1:] #ignore <start>\n",
    "\n",
    "        # Decoder Embeddings\n",
    "#         print(decoder_input.shape)  # batch_size X sequence_length\n",
    "#         decoder_emb_inp = tf.expand_dims(decoder_input, -1)  # add the feature dimension, 1\n",
    "#         print(decoder_emb_inp.shape) # batch_size X sequence_length X 1\n",
    "        decoder_emb_inp = decoderNetwork.decoder_embedding(decoder_input)\n",
    "#         print(decoder_emb_inp.shape) # batch_size X sequence_length X rnn_size\n",
    "\n",
    "#         print(decoder_input, decoder_output, decoder_emb_inp)\n",
    "    \n",
    "        #Setting up decoder memory from encoder output and Zero State for AttentionWrapperState\n",
    "        decoder_initial_state = encoder_state\n",
    "    \n",
    "        #BasicDecoderOutput        \n",
    "        outputs, _, _ = decoderNetwork.decoder(decoder_emb_inp, \n",
    "                                               initial_state=decoder_initial_state)\n",
    "#         print('C0:', tf.math.count_nonzero(outputs), outputs.shape[0]*outputs.shape[1])\n",
    "    \n",
    "        # outputs is batch_size X sequence_length X RNN dimension\n",
    "        logits = decoderNetwork.dense_layer(outputs)  # outputs.rnn_output\n",
    "#         print('C1:', tf.math.count_nonzero(logits))\n",
    "\n",
    "        # squeeze is required only for one output feature\n",
    "#         logits = tf.squeeze(logits, axis=-1)\n",
    "#         print(logits.shape, decoder_output.shape)  # batch_size X sequence_length\n",
    "#         print(logits)\n",
    "#         print('C2:', tf.math.count_nonzero(logits))\n",
    "        \n",
    "        #Calculate loss\n",
    "        loss = loss_function(logits, decoder_output)\n",
    "\n",
    "    #Returns the list of all layer variables / weights.\n",
    "    variables = encoderNetwork.trainable_variables + decoderNetwork.trainable_variables  \n",
    "    \n",
    "    # differentiate loss wrt variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    #grads_and_vars – List of(gradient, variable) pairs.\n",
    "    grads_and_vars = zip(gradients,variables)\n",
    "    optimizer.apply_gradients(grads_and_vars)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "#RNN LSTM hidden and memory state initializer\n",
    "def initialize_initial_state():\n",
    "    if bidirectional:\n",
    "        return [tf.zeros((BATCH_SIZE, rnn_units)), tf.zeros((BATCH_SIZE, rnn_units)), \n",
    "                tf.zeros((BATCH_SIZE, rnn_units)), tf.zeros((BATCH_SIZE, rnn_units))]        \n",
    "    else:\n",
    "        return [tf.zeros((BATCH_SIZE, rnn_units)), tf.zeros((BATCH_SIZE, rnn_units))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = x_norm.shape[-1]\n",
    "encoderNetwork = EncoderNetwork(rnn_units)\n",
    "decoderNetwork = DecoderNetwork2(rnn_units, num_features)\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch, X_train.shape, X_train.shape[0]/BATCH_SIZE, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_print = int(steps_per_epoch/10)\n",
    "for i in range(1, epochs+1):\n",
    "\n",
    "    encoder_initial_cell_state = initialize_initial_state()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for ( batch , (input_batch, output_batch)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(input_batch, output_batch, encoder_initial_cell_state)\n",
    "        total_loss += batch_loss\n",
    "        if (batch+1)%(batch_print) == 0:\n",
    "            now = datetime.now()\n",
    "            dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "            print(f\"total loss: {batch_loss.numpy()} epoch-{i}, batch-{batch+1}, time: {dt_string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(BATCH_SIZE, drop_remainder=False)\n",
    "example_X, example_Y = next(iter(dataset_test))\n",
    "print(example_X.shape) \n",
    "print(example_Y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_X, example_Y = next(iter(dataset))\n",
    "# print(example_X.shape) \n",
    "# print(example_Y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = example_X\n",
    "inference_batch_size = input_sequences.shape[0]\n",
    "if bidirectional:\n",
    "    encoder_initial_cell_state = [tf.zeros((inference_batch_size, rnn_units)),\n",
    "                                  tf.zeros((inference_batch_size, rnn_units)),\n",
    "                                  tf.zeros((inference_batch_size, rnn_units)),\n",
    "                                  tf.zeros((inference_batch_size, rnn_units))]\n",
    "else:\n",
    "    encoder_initial_cell_state = [tf.zeros((inference_batch_size, rnn_units)),\n",
    "                                  tf.zeros((inference_batch_size, rnn_units))]\n",
    "# encoder_emb_inp = tf.expand_dims(input_sequences, -1)\n",
    "encoder_emb_inp = input_sequences\n",
    "encoder_emb_inp = encoderNetwork.encoder_embedding(encoder_emb_inp)  # just a linear layer\n",
    "\n",
    "if bidirectional:\n",
    "    _, state_hf, state_hb, state_cf, state_cb = encoderNetwork.encoder_rnnlayer(encoder_emb_inp, \n",
    "                                                    initial_state = encoder_initial_cell_state)\n",
    "    state_h = encoderNetwork.state_converter(tf.concat([state_hf, state_hb], axis=-1))\n",
    "    state_c = encoderNetwork.state_converter(tf.concat([state_cf, state_cb], axis=-1))\n",
    "else:    \n",
    "    _, state_h, state_c = encoderNetwork.encoder_rnnlayer(encoder_emb_inp, \n",
    "                                                    initial_state = encoder_initial_cell_state)\n",
    "\n",
    "#[last step activations,last memory_state] of encoder passed as input to decoder Network\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "#Setting up decoder memory from encoder output and Zero State for AttentionWrapperState\n",
    "\n",
    "# decoder_input = tf.expand_dims(example_Y[:,0], -1)\n",
    "decoder_input = example_Y[:,0,:]\n",
    "\n",
    "# decoder_input = tf.expand_dims([0]* inference_batch_size,1)\n",
    "# decoder_emb_inp = tf.expand_dims(decoder_input, -1)  # add the feature dimension, 1\n",
    "decoder_emb_inp = tf.expand_dims(decoder_input, axis=-2) # add the feature dimension\n",
    "# print(decoder_emb_inp.shape) # batch_size X sequence_length X 1\n",
    "decoder_emb_inp = decoderNetwork.decoder_embedding(decoder_emb_inp)\n",
    "# print(decoder_emb_inp)\n",
    "\n",
    "Ty = example_Y.shape[1]\n",
    "maximum_iterations = Ty\n",
    "inputs = decoder_emb_inp\n",
    "state = encoder_state\n",
    "predictions = np.empty((inference_batch_size, 0, 3), dtype = np.int32)\n",
    "\n",
    "for jj in range(Ty):\n",
    "    outputs, state_h, state_c = decoderNetwork.decoder(inputs, state)\n",
    "    outputs = decoderNetwork.dense_layer(outputs)\n",
    "    \n",
    "#     current_prediction = tf.squeeze(outputs, axis=-1)\n",
    "    current_prediction = outputs\n",
    "    predictions = np.append(predictions, current_prediction, axis = -2)\n",
    "    inputs = decoderNetwork.decoder_embedding(outputs)\n",
    "    state = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def plot_sample(example_X, example_Y, num_samples=1):\n",
    "    len_x, len_y = example_X.shape[1], example_Y.shape[1]\n",
    "    shifted_x = [x+len_x for x in range(len_y)]\n",
    "    for ii in range(num_samples):\n",
    "        cnum = random.randint(0, len(example_X))\n",
    "        f = plt.figure(ii+1, figsize=(15,4))\n",
    "        ax1 = f.add_subplot(131)\n",
    "        ax2 = f.add_subplot(132)\n",
    "        ax3 = f.add_subplot(133)\n",
    "\n",
    "        ax1.plot(example_X[cnum,:, 0])\n",
    "        ax1.plot(shifted_x, example_Y[cnum,:,0])  # , 'bo--'\n",
    "        ax1.plot(shifted_x, predictions[cnum,:,0])  # , 'r+'\n",
    "        ax1.title.set_text('Power')\n",
    "\n",
    "        ax2.plot(example_X[cnum,:, 1])\n",
    "        ax2.plot(shifted_x, example_Y[cnum,:,1])  # , 'bo--'\n",
    "        ax2.plot(shifted_x, predictions[cnum,:,1])  # , 'r+'\n",
    "        ax2.title.set_text('Temperature')\n",
    "\n",
    "        ax3.plot(example_X[cnum,:, 2])\n",
    "        ax3.plot(shifted_x, example_Y[cnum,:,2])  # , 'bo--'\n",
    "        ax3.plot(shifted_x, predictions[cnum,:,2])  # , 'r+'\n",
    "        ax3.title.set_text('Irradiance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 256 - 256 - 512 - mse\n",
    "plot_sample(example_X, example_Y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 128 - 128 - 256 - mae\n",
    "plot_sample(example_X, example_Y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
